---
title: "AI Tools for Data Science and Statistics"
subtitle: "Advanced Topics in Biostatistics (140.850), 3rd Term, 2025–2026"
date: last-modified
format:
  html:
    toc: false
---

Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health

**Instructor:** Erik Westlund ([ewestlund@jhu.edu](mailto:ewestlund@jhu.edu))

**Dates:** February 19, February 26, March 5, March 12, 2026

**Time:** 9:00–10:20 AM ET

* [Syllabus](course_docs/syllabus.html)
* [Course Project](course_docs/course-project.html)
* [GitHub Repository](https://github.com/erikwestlund/aitools)

## Sessions

### Session 1 (February 19): Foundations: History, Today, and Ethics

We will share our experiences using AI and study the foundations of AI tools. We will discuss ethics/concerns people have with using the tools.

- [Slides](slides/01-foundations.html)

### Session 2 (February 26): Tools Introduction

We will focus on practical tool use for biostatistics, with an emphasis on responsible use and verification.

* Model selection basics: model size, reasoning vs instruct behavior, local vs cloud, and cost/access tradeoffs
* Interfaces and harnesses: chat tools, browser/IDE agents, and CLI agents (Claude Code, Codex, OpenCode)
* One standardized workflow: compare chat/simple/detailed prompts across harnesses and models on synthetic maternal health data
* Safety guardrails: no PHI in external tools, context boundaries, and verify-before-trust

- [Slides](slides/02-tools-introduction.html)
- **Due before class:** Email course project topic to [ewestlund@jhu.edu](mailto:ewestlund@jhu.edu)

### Session 3 (March 5): AI-Assisted Statistical Workflows

We will discuss how to use these tools to:

* Summarize datasets
* Generate synthetic/simulated data
* Build models

We will pay special attention to how to work with PHI using these tools

- Slides [coming soon]
- **Due:** Make progress on moonshot; prepare for check-in

### Session 4 (March 12): Synthesis and Looking Forward

We will spend most of this session sharing our experiences with our projects, but will leave it open to address lingering questions.

- Slides [coming soon]
- **Due:** [Course project](course_docs/course-project.html): project materials and 2–3 page reflection; in-class share

## Course Readings

While I am not requiring you to read these papers, I am providing them for reference. The slides often reference them using the identifying numbers below. The concepts/problems these papers investigate and discuss are still relevant. Nevertheless, both the speed at which LLM technology is advancing as well the artificiality of many of the benchmarks should lead you to interpret presented data with caution.

### Published

1. Ni, A., Yin, P., Zhao, Y., Riddell, M., Feng, T., Shen, R., Yin, S., Liu, Y., Yavuz, S., Xiong, C., Joty, S., Zhou, Y., Radev, D., & Cohan, A. (2024). L2CEval: Evaluating language-to-code generation capabilities of large language models. *Transactions of the Association for Computational Linguistics*, 12, 1311–1329. [doi:10.1162/tacl_a_00705](https://doi.org/10.1162/tacl_a_00705)

2. Jiang, J., Wang, F., Shen, J., Kim, S., & Kim, S. (2025). A survey on large language models for code generation. *ACM Transactions on Software Engineering and Methodology*. [doi:10.1145/3747588](https://doi.org/10.1145/3747588)

3. Chen, S., Pusarla, P., & Ray, B. (2025). DyCodeEval: Dynamic benchmarking of reasoning capabilities in code large language models under data contamination. *Proceedings of the 42nd International Conference on Machine Learning (ICML)*, PMLR 267, 8890–8909. [proceedings.mlr.press](https://proceedings.mlr.press/v267/chen25ba.html)

4. Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., & Steinhardt, J. (2021). Measuring mathematical problem solving with the MATH dataset. *Proceedings of NeurIPS 2021, Datasets and Benchmarks Track*. [openreview.net](https://openreview.net/forum?id=7Bywt2mQsCe)

5. Phan, L., Gatti, A., Han, Z., Li, N., Hu, J., Zhang, H., Zhang, C. B. C., Shaaban, M., Ling, J., Shi, S., Choi, M., Agrawal, A., Chopra, A., Khoja, A., Kim, R., Ren, R., Hausenloy, J., Zhang, O., Mazeika, M., Yue, S., Wang, A., & Hendrycks, D. (2025). Humanity's Last Exam. *Nature*. [doi:10.1038/s41586-025-09962-4](https://doi.org/10.1038/s41586-025-09962-4)

6. Tambon, F., Moradi Dakhel, A., Nikanjam, A., Khomh, F., Desmarais, M. C., & Antoniol, G. (2025). Bugs in large language models generated code: An empirical study. *Empirical Software Engineering*, 30(3). [doi:10.1007/s10664-025-10614-4](https://doi.org/10.1007/s10664-025-10614-4)

7. Pan, R., Ibrahimzada, A. R., Krishna, R., Sankar, D., Pougeum Wassi, L., Merler, M., Sobolev, B., Pavuluri, R., Sinha, S., & Jabbarvand, R. (2024). Lost in translation: A study of bugs introduced by large language models while translating code. *Proceedings of ICSE '24*. [doi:10.1145/3597503.3639226](https://doi.org/10.1145/3597503.3639226)

8. Tang, N., Chen, M., Ning, Z., Bansal, A., Huang, Y., McMillan, C., & Li, T. J.-J. (2024). Developer behaviors in validating and repairing LLM-generated code using eye tracking and IDE actions. *IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC 2024)*, 40–46. [doi:10.1109/VL/HCC60511.2024.00015](https://doi.org/10.1109/VL/HCC60511.2024.00015)

9. Zhou, X., Liang, P., Zhang, B., Li, Z., Ahmad, A., Shahin, M., & Waseem, M. (2024). Exploring the problems, their causes and solutions of AI pair programming: A study on GitHub and Stack Overflow. *Journal of Systems and Software*, 219, 112204. [doi:10.1016/j.jss.2024.112204](https://doi.org/10.1016/j.jss.2024.112204)

10. Tang, L., Liu, J., Liu, Z., Yang, X., & Bao, L. (2025). LLM4SZZ: Enhancing SZZ algorithm with context-enhanced assessment on large language models. *Proceedings of the ACM on Software Engineering*, 2(ISSTA), 343–365. [doi:10.1145/3728885](https://doi.org/10.1145/3728885)

11. Dinh, T., Zhao, J., Tan, S., Negrinho, R., Lausen, L., Zha, S., & Karypis, G. (2023). Large language models of code fail at completing code with potential bugs. *Proceedings of NeurIPS 2023*. [proceedings.neurips.cc](https://proceedings.neurips.cc/paper_files/paper/2023/hash/819cebb05f993840e8a52d7564c5c282-Abstract-Conference.html)

### Preprints

12. Fu, L., Chai, H., Du, K., Zhang, W., Luo, S., Lin, J., Fang, Y., Rui, R., Guan, H., Liu, J., Qi, S., Fan, L., Lei, J., Liu, Y., Wang, J., Zhang, K., Zhang, W., & Yu, Y. (2024). CodeApex: A bilingual programming evaluation benchmark for large language models. [arXiv:2309.01940](https://arxiv.org/abs/2309.01940)

13. Lu, Y., Yang, R., Zhang, Y., Yu, S., Dai, R., Wang, Z., Xiang, J., E, W., Gao, S., Ruan, X., Huang, Y., Xi, C., Hu, H., Fu, Y., Yu, Q., Wei, X., Gu, J., Sun, R., Jia, J., & Zhou, F. (2025). StatEval: A comprehensive benchmark for large language models in statistics. [arXiv:2510.09517](https://arxiv.org/abs/2510.09517)

14. Fu, Y., Ou, L., Chen, M., Wan, Y., Peng, H., & Khot, T. (2023). Chain-of-Thought Hub: A continuous effort to measure large language models' reasoning performance. [arXiv:2305.17306](https://arxiv.org/abs/2305.17306)

15. Opu, M. N. I., Wang, S., & Chowdhury, S. (2025). LLM-based detection of tangled code changes for higher-quality method-level bug datasets. [arXiv:2505.08263](https://arxiv.org/abs/2505.08263)

16. Islam, N., Ayon, R. S., Thomas, D. G., Ahmed, S., & Wardat, M. (2026). When agents fail: A comprehensive study of bugs in LLM agents with automated labeling. [arXiv:2601.15232](https://arxiv.org/abs/2601.15232)

17. Gloaguen, T., Mundler, N., Muller, M., Raychev, V., & Vechev, M. (2026). Evaluating AGENTS.md: Are repository-level context files helpful for coding agents? [arXiv:2602.11988](https://arxiv.org/abs/2602.11988)

## Further Reading

### Code Quality, Bugs, and Security

18. Pearce, H., Ahmad, B., Tan, B., Dolan-Gavitt, B., & Karri, R. (2022). Asleep at the keyboard? Assessing the security of GitHub Copilot's code contributions. *IEEE Symposium on Security and Privacy (S&P 2022)*, 754–768. [doi:10.1109/SP46214.2022.9833571](https://doi.org/10.1109/SP46214.2022.9833571)

19. Perry, N., Srivastava, M., Kumar, D., & Boneh, D. (2023). Do users write more insecure code with AI assistants? *ACM Conference on Computer and Communications Security (CCS 2023)*. [doi:10.1145/3576915.3623157](https://doi.org/10.1145/3576915.3623157)

20. Sandoval, G., Pearce, H., Nys, T., Karri, R., Garg, S., & Dolan-Gavitt, B. (2023). Lost at C: A user study on the security implications of large language model code assistants. *USENIX Security Symposium 2023*, 2205–2222. [usenix.org](https://www.usenix.org/conference/usenixsecurity23/presentation/sandoval)

21. Jesse, K., Ahmed, T., Devanbu, P., & Morgan, E. (2023). Large language models and simple, stupid bugs. *IEEE/ACM 20th International Conference on Mining Software Repositories (MSR 2023)*, 563–575. [doi:10.1109/MSR59073.2023.00082](https://doi.org/10.1109/MSR59073.2023.00082)

22. Asare, O., Nagappan, M., & Asokan, N. (2023). Is GitHub's Copilot as bad as humans at introducing vulnerabilities in code? *Empirical Software Engineering*, 28, 129. [doi:10.1007/s10664-023-10380-1](https://doi.org/10.1007/s10664-023-10380-1)

23. Liu, J., Xia, C. S., Wang, Y., & Zhang, L. (2023). Is your code generated by ChatGPT really correct? Rigorous evaluation of large language models for code generation. *Proceedings of NeurIPS 2023*. [proceedings.neurips.cc](https://proceedings.neurips.cc/paper_files/paper/2023/hash/43e9d647ccd3e4b7b5baab53f0368686-Abstract-Conference.html)

24. Du, X., Liu, M., Wang, K., Wang, H., et al. (2024). Evaluating large language models in class-level code generation. *Proceedings of ICSE 2024*. [doi:10.1145/3597503.3639219](https://doi.org/10.1145/3597503.3639219)

### AI-Assisted Programming

25. Vaithilingam, P., Zhang, T., & Glassman, E. L. (2022). Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models. *CHI Conference on Human Factors in Computing Systems Extended Abstracts (CHI EA '22)*. [doi:10.1145/3491101.3519665](https://doi.org/10.1145/3491101.3519665)

26. Nguyen, N. & Nadi, S. (2022). An empirical evaluation of GitHub Copilot's code suggestions. *19th International Conference on Mining Software Repositories (MSR '22)*. [doi:10.1145/3524842.3528470](https://doi.org/10.1145/3524842.3528470)

27. Dakhel, A. M., Majdinasab, V., Nikanjam, A., Khomh, F., Desmarais, M. C., & Jiang, Z. M. J. (2023). GitHub Copilot AI pair programmer: Asset or liability? *Journal of Systems and Software*, 203, 111734. [doi:10.1016/j.jss.2023.111734](https://doi.org/10.1016/j.jss.2023.111734)

28. Barke, S., James, M. B., & Polikarpova, N. (2023). Grounded Copilot: How programmers interact with code-generating models. *Proceedings of the ACM on Programming Languages (OOPSLA)*, 7(OOPSLA1), 85–111. [doi:10.1145/3586030](https://doi.org/10.1145/3586030)

29. Ziegler, A., Kalliamvakou, E., Li, X. A., Rice, A., et al. (2024). Measuring GitHub Copilot's impact on productivity. *Communications of the ACM*, 67(3), 54–63. [doi:10.1145/3633453](https://doi.org/10.1145/3633453)

30. Liang, J. T., Yang, C., & Myers, B. A. (2024). A large-scale survey on the usability of AI programming assistants: Successes and challenges. *Proceedings of ICSE 2024*. [doi:10.1145/3597503.3608128](https://doi.org/10.1145/3597503.3608128)

31. Murali, V., Maddila, C., Ahmad, I., Bolin, M., et al. (2024). AI-assisted code authoring at scale: Fine-tuning, deploying, and mixed methods evaluation. *Proceedings of the ACM on Software Engineering (PACMSE/FSE)*, 1(FSE), 1066–1085. [doi:10.1145/3643774](https://doi.org/10.1145/3643774)

### Benchmarks and Evaluation

32. Jimenez, C. E., Yang, J., Wettig, A., Yao, S., Pei, K., Press, O., & Narasimhan, K. R. (2024). SWE-bench: Can language models resolve real-world GitHub issues? *ICLR 2024* (Oral). [openreview.net](https://openreview.net/forum?id=VTF8yNQM66)

33. Lai, Y., Li, C., Wang, Y., Zhang, T., Zhong, R., Zettlemoyer, L., Yih, W., Fried, D., Wang, S., & Yu, T. (2023). DS-1000: A natural and reliable benchmark for data science code generation. *Proceedings of ICML 2023*, PMLR 202, 18319–18345. [proceedings.mlr.press](https://proceedings.mlr.press/v202/lai23b.html)

### Reasoning Capabilities and Limitations

34. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q. V., & Zhou, D. (2022). Chain-of-thought prompting elicits reasoning in large language models. *Proceedings of NeurIPS 2022*. [proceedings.neurips.cc](https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html)

35. Valmeekam, K., Marquez, M., Sreedharan, S., & Kambhampati, S. (2023). On the planning abilities of large language models — a critical investigation. *Proceedings of NeurIPS 2023* (Spotlight). [proceedings.neurips.cc](https://proceedings.neurips.cc/paper_files/paper/2023/hash/efb2072a358cefb75886a315a6fcf880-Abstract-Conference.html)

36. Kambhampati, S., Valmeekam, K., Guan, L., Verma, M., Stechly, K., et al. (2024). Position: LLMs can't plan, but can help planning in LLM-Modulo frameworks. *Proceedings of ICML 2024* (Spotlight), PMLR 235, 22895–22907. [proceedings.mlr.press](https://proceedings.mlr.press/v235/kambhampati24a.html)

### Ethics and Responsible AI

37. Weidinger, L., Mellor, J., Rauh, M., Griffin, C., et al. (2022). Taxonomy of risks posed by language models. *ACM Conference on Fairness, Accountability, and Transparency (FAccT 2022)*. [doi:10.1145/3531146.3533088](https://doi.org/10.1145/3531146.3533088)

38. Hosseini, M., Resnik, D. B., & Holmes, K. (2023). The ethics of disclosing the use of artificial intelligence tools in writing scholarly manuscripts. *Research Ethics*, 19(4), 449–465. [doi:10.1177/17470161231180449](https://doi.org/10.1177/17470161231180449)

39. Liao, Q. V. & Vaughan, J. W. (2024). AI transparency in the age of LLMs: A human-centered research roadmap. *Harvard Data Science Review*, Special Issue 5. [doi:10.1162/99608f92.8036d03b](https://doi.org/10.1162/99608f92.8036d03b)

### Human Factors in AI-Assisted Coding

40. Mozannar, H., Bansal, G., Fourney, A., & Horvitz, E. (2024). Reading between the lines: Modeling user behavior and costs in AI-assisted programming. *CHI 2024* (Honorable Mention). [doi:10.1145/3613904.3641936](https://doi.org/10.1145/3613904.3641936)

41. Ferdowsi, K., Huang, R., James, M. B., Polikarpova, N., & Lerner, S. (2024). Validating AI-generated code with live programming. *CHI 2024*. [doi:10.1145/3613904.3642495](https://doi.org/10.1145/3613904.3642495)
